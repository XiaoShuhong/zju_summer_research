{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2f8366d-6821-4cf3-aa61-b1e00925cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from cv2 import cv2 as cv2\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "from moviepy.editor import VideoFileClip\n",
    "import os\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaa5ba6-a077-49d9-82f2-42db6e30672b",
   "metadata": {},
   "source": [
    "## parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ceafaa28-e063-49c3-aabf-41a3b69c601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_factor=10 ## num of detection within each second\n",
    "match_ratio=0.3 ##the distance ratio thershold between best match and second match\n",
    "good_match_rate=0.7 ##the rate of matches to be chosen in all\n",
    "ransacReprojThreshold=5\n",
    "min_match_count=5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9df8e55-e84a-4287-ac94-c366f61ae128",
   "metadata": {},
   "source": [
    "## anotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cbf03a-5ffe-4863-bdbd-b7dfd7e94736",
   "metadata": {},
   "source": [
    "for keypoint, attribute to use are:\n",
    "    pt \n",
    "    angle\n",
    "    response\n",
    "    size\n",
    "    octave\n",
    "    class_idï¼šobject\n",
    "for match, attribute to use are:\n",
    "    distance\n",
    "    queryIdx\n",
    "    trainIdx\n",
    "    imgIdx\n",
    "    \n",
    "    print(kp1[i.queryIdx].pt) location before move\n",
    "    print(kp2[i.trainIdx].pt) location after move"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76bd944-25de-483a-9313-86be164c36d4",
   "metadata": {},
   "source": [
    "## test begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b679ac6e-49e6-4886-a825-fcfa44f95526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    ##load test video\n",
    "    video=os.path.abspath(os.curdir)+'/click_in.mp4'\n",
    "    videoCapture = cv2.VideoCapture(video)\n",
    "    \n",
    "    ##detect for gap_factor #gap_dected frames\n",
    "    fps = videoCapture.get(cv2.CAP_PROP_FPS)\n",
    "    print(fps)\n",
    "    gap_dected=int(fps//gap_factor)\n",
    "    \n",
    "    ##load first frame\n",
    "    success, frame_old = videoCapture.read()\n",
    "    i,j=0,0\n",
    "    _SaveImage(frame_old,os.path.abspath(os.curdir)+'/test',j)\n",
    "    print('save image:',i)\n",
    "    \n",
    "    predict=deque([],maxlen=gap_factor)\n",
    "    \n",
    "    while success:\n",
    "        i+=1\n",
    "    ##finish process if all frames loaded\n",
    "        success, frame_new = videoCapture.read()\n",
    "        if success==False:\n",
    "            print('vedio detection finish')\n",
    "#           sys.exit() \n",
    "            return \n",
    "        if (i % gap_dected == 0):\n",
    "            j+=1\n",
    "            _SaveImage(frame_new,os.path.abspath(os.curdir)+'/test',j)\n",
    "            print('save image:',i)\n",
    "            \n",
    "    ##predict \n",
    "            if _AlignImages(frame_old,frame_new) != None:\n",
    "                predict.append(_AlignImages(frame_old,frame_new))\n",
    "                if len(predict)==gap_factor:\n",
    "                    res=_Predict(predict)\n",
    "                    print(i//30,'s',i%30,'frame',res)\n",
    "            \n",
    "            \n",
    "        frame_old=frame_new\n",
    "    \n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7e61a1a1-275a-41d6-84af-cd5822e43dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _SaveImage(image,addr,num):\n",
    "    address = addr +'/'+ str(num)+ '.jpg'\n",
    "    cv2.imwrite(address,image)\n",
    "\n",
    "def _AlignImages(img1,img2):\n",
    "    # initiate ORB detector\n",
    "    orb = cv2.ORB_create(5000)\n",
    "    \n",
    "    ##check bilateral banner, eliminate stick part\n",
    "#     up_idx,down_idx=_SplitImage(img1,img2)\n",
    "#     img1 = img1[up_idx:down_idx,:]\n",
    "#     img2= img2[up_dx:down_idx,:]\n",
    "    img1 = img1[80:440,:]\n",
    "    img2 = img2[80:440,:]\n",
    "    \n",
    "    ##find the keypoints and descriptors with ORB\n",
    "    kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "    kp2, des2 = orb.detectAndCompute(img2,None)\n",
    "    if des2== None: \n",
    "        return None\n",
    "    \n",
    "    ##match with Brute-Force\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "    ##find best 2 matches for each kp\n",
    "    matches = bf.knnMatch(des1, trainDescriptors = des2, k = 2)\n",
    "    print(len(matches))\n",
    "    ##ratio test\n",
    "    good = [m for (m,n) in matches if m.distance < match_ratio*n.distance]\n",
    "    ##sort and choose the best part of matches\n",
    "#     good = sorted(good, key = lambda x:x.distance)\n",
    "#     good = good[:int(len(good) * good_match_rate)]\n",
    "    \n",
    "    if len(good)>min_match_count:\n",
    "        src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        ##find (3x3) transform matrix\n",
    "        M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,ransacReprojThreshold)\n",
    "        t_x = M[0][2]\n",
    "        t_y = M[1][2]\n",
    "        return (t_x,t_y)\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "        \n",
    "\n",
    "def _Predict(predict):\n",
    "    res=[]\n",
    "    for p in predict:\n",
    "        res.append(__Pattern(p[0],p[1]))\n",
    "    return res\n",
    "    \n",
    "def __Pattern(t_x,t_y):\n",
    "    if abs(t_x)<1 and abs(t_y)<1:\n",
    "#         print('stop')\n",
    "        return 'stop'\n",
    "    elif abs(t_x/t_y)>20:\n",
    "        if (t_x>0):\n",
    "#             print('down')\n",
    "            return 'right'\n",
    "        else:\n",
    "#             print('up')\n",
    "            return 'left'\n",
    "    \n",
    "    elif abs(t_y/t_x)>15:\n",
    "#         print('up,down')\n",
    "        if (t_y>0):\n",
    "#             print('down')\n",
    "            return 'down'\n",
    "        else:\n",
    "#             print('up')\n",
    "            return 'up'\n",
    "          \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbf451f-07bf-4ead-bb4e-fb0cafc5eaae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cb36f190-6b23-46ab-9bb7-bf61f9e3a91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.25\n",
      "save image: 0\n",
      "save image: 2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-46-0084b9ed4911>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m##predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0m_AlignImages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe_old\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe_new\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m                 \u001b[0mpredict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_AlignImages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe_old\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe_new\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mgap_factor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-58-a1ad322f13ba>\u001b[0m in \u001b[0;36m_AlignImages\u001b[1;34m(img1, img2)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mkp1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdes1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mkp2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdes2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mdes2\u001b[0m\u001b[1;33m==\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1844827e-9ece-4959-9738-13fd2e855e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "995d33b3-9ba8-4d53-b66f-0a2ced4ddb9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d26b0c05-230b-420d-8a49-cb0165573d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=deque([],maxlen=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "138365e8-81d4-41c7-a1f3-417e241fe11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.append(1)\n",
    "a.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "692f3e1e-10b8-4dce-9807-4b4963c89677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "None\n",
      "1\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    print(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3bd6a12f-0557-42c4-b081-e946c5f25531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "634dd2e1-c4ba-48dc-8c92-facffa43ab1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stop'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4425795a-522d-4e49-bd01-cc1325e1bf39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
