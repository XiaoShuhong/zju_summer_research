{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b2f8366d-6821-4cf3-aa61-b1e00925cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from cv2 import cv2 as cv2\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "from moviepy.editor import VideoFileClip\n",
    "import os\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaa5ba6-a077-49d9-82f2-42db6e30672b",
   "metadata": {},
   "source": [
    "## parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ceafaa28-e063-49c3-aabf-41a3b69c601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_factor=5 ## num of detection within each second\n",
    "match_ratio=0.3 ##the distance ratio thershold between best match and second match\n",
    "good_match_rate=0.7 ##the rate of matches to be chosen in all\n",
    "ransacReprojThreshold=5\n",
    "min_match_count=5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9df8e55-e84a-4287-ac94-c366f61ae128",
   "metadata": {},
   "source": [
    "## anotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cbf03a-5ffe-4863-bdbd-b7dfd7e94736",
   "metadata": {},
   "source": [
    "for keypoint, attribute to use are:\n",
    "    pt \n",
    "    angle\n",
    "    response\n",
    "    size\n",
    "    octave\n",
    "    class_idï¼šobject\n",
    "for match, attribute to use are:\n",
    "    distance\n",
    "    queryIdx\n",
    "    trainIdx\n",
    "    imgIdx\n",
    "    \n",
    "    print(kp1[i.queryIdx].pt) location before move\n",
    "    print(kp2[i.trainIdx].pt) location after move"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76bd944-25de-483a-9313-86be164c36d4",
   "metadata": {},
   "source": [
    "## test begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b679ac6e-49e6-4886-a825-fcfa44f95526",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    ##load test video\n",
    "    video=os.path.abspath(os.curdir)+'/taobao_test1.mp4'\n",
    "    videoCapture = cv2.VideoCapture(video)\n",
    "    \n",
    "    ##detect for gap_factor #gap_dected frames\n",
    "    fps = videoCapture.get(cv2.CAP_PROP_FPS)\n",
    "    gap_dected=int(fps//gap_factor)\n",
    "    \n",
    "    ##load first frame\n",
    "    success, frame_old = videoCapture.read()\n",
    "    i,j=0,0\n",
    "    _SaveImage(frame_old,os.path.abspath(os.curdir)+'/test',j)\n",
    "    print('save image:',i)\n",
    "    \n",
    "    predict=deque()\n",
    "    \n",
    "    while success:\n",
    "        i+=1\n",
    "    ##finish process if all frames loaded\n",
    "        success, frame_new = videoCapture.read()\n",
    "        if success==False:\n",
    "            print('vedio detection finish')\n",
    "#           sys.exit() \n",
    "            return \n",
    "        if (i % gap_dected == 0):\n",
    "            j+=1\n",
    "            _SaveImage(frame_new,os.path.abspath(os.curdir)+'/test',j)\n",
    "            print('save image:',i)\n",
    "            \n",
    "    ##predict every second\n",
    "        if len(predict)<gap_factor:\n",
    "            _AlignImages(frame_old,frame_new)\n",
    "        if len(predict)==gap_factor\n",
    "            _Predict(predict)\n",
    "            predict.clear()\n",
    "            \n",
    "        frame_old=frame_new\n",
    "    \n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7e61a1a1-275a-41d6-84af-cd5822e43dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _SaveImage(image,addr,num):\n",
    "    address = addr +'/'+ str(num)+ '.jpg'\n",
    "    cv2.imwrite(address,image)\n",
    "\n",
    "def _AlignImages(img1,img2):\n",
    "    # initiate ORB detector\n",
    "    orb = cv2.ORB_create(5000)\n",
    "    \n",
    "    ##check bilateral banner, eliminate stick part\n",
    "#     up_idx,down_idx=_SplitImage(img1,img2)\n",
    "#     img1 = img1[up_idx:down_idx,:]\n",
    "#     img2= img2[up_dx:down_idx,:]\n",
    "    img1 = img1[80:440,:]\n",
    "    img2 = img2[80:440,:]\n",
    "    \n",
    "    ##find the keypoints and descriptors with ORB\n",
    "    kp1, des1 = orb.detectAndCompute(img1,None)\n",
    "    kp2, des2 = orb.detectAndCompute(img2,None)\n",
    "    \n",
    "    ##match with Brute-Force\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "    ##find best 2 matches for each kp\n",
    "    matches = bf.knnMatch(des1, trainDescriptors = des2, k = 2)\n",
    "    ##ratio test\n",
    "    good = [m for (m,n) in matches if m.distance < match_ratio*n.distance]\n",
    "    ##sort and choose the best part of matches\n",
    "#     good = sorted(good, key = lambda x:x.distance)\n",
    "#     good = good[:int(len(good) * good_match_rate)]\n",
    "    \n",
    "    if len(good)>min_match_count:\n",
    "        src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "        ##find (3x3) transform matrix\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,ransacReprojThreshold)\n",
    "        t_x = M[0][2]\n",
    "        t_y = M[1][2]\n",
    "        _Pattern(t_x,t_y)\n",
    "        \n",
    "        \n",
    "        \n",
    "def __Pattern(t_x,t_y):\n",
    "    if abs(t_x)<1 and abs(t_y)<1:\n",
    "        print('stop')\n",
    "        return \n",
    "    elif abs(t_x/t_y)>20:\n",
    "        print('left,right')\n",
    "        return\n",
    "    elif abs(t_y/t_x)>20:\n",
    "        print('up,down')\n",
    "        if (t_y>0):\n",
    "            print('down')\n",
    "        else:\n",
    "            print('up')\n",
    "        return \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cdbf451f-07bf-4ead-bb4e-fb0cafc5eaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=deque()\n",
    "for i in range(10):\n",
    "    a.append(i)\n",
    "a.clear()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cb36f190-6b23-46ab-9bb7-bf61f9e3a91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save image: 0\n",
      "save image: 10\n",
      "save image: 20\n",
      "save image: 30\n",
      "save image: 40\n",
      "save image: 50\n",
      "save image: 60\n",
      "save image: 70\n",
      "save image: 80\n",
      "save image: 90\n",
      "save image: 100\n",
      "save image: 110\n",
      "save image: 120\n",
      "save image: 130\n",
      "save image: 140\n",
      "save image: 150\n",
      "save image: 160\n",
      "save image: 170\n",
      "save image: 180\n",
      "save image: 190\n",
      "save image: 200\n",
      "save image: 210\n",
      "save image: 220\n",
      "save image: 230\n",
      "save image: 240\n",
      "save image: 250\n",
      "save image: 260\n",
      "save image: 270\n",
      "save image: 280\n",
      "save image: 290\n",
      "save image: 300\n",
      "save image: 310\n",
      "save image: 320\n",
      "save image: 330\n",
      "save image: 340\n",
      "save image: 350\n",
      "save image: 360\n",
      "save image: 370\n",
      "save image: 380\n",
      "save image: 390\n",
      "save image: 400\n",
      "save image: 410\n",
      "save image: 420\n",
      "save image: 430\n",
      "save image: 440\n",
      "save image: 450\n",
      "save image: 460\n",
      "save image: 470\n",
      "save image: 480\n",
      "save image: 490\n",
      "save image: 500\n",
      "save image: 510\n",
      "save image: 520\n",
      "save image: 530\n",
      "save image: 540\n",
      "save image: 550\n",
      "save image: 560\n",
      "save image: 570\n",
      "save image: 580\n",
      "save image: 590\n",
      "save image: 600\n",
      "save image: 610\n",
      "save image: 620\n",
      "save image: 630\n",
      "save image: 640\n",
      "save image: 650\n",
      "save image: 660\n",
      "save image: 670\n",
      "save image: 680\n",
      "vedio detection finish\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1844827e-9ece-4959-9738-13fd2e855e56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
